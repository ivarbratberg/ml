{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['items.csv', 'item_categories.csv', 'sales_train.csv', 'shops.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c1d6632e58738a9d1537c482b63059ef4111cdc"
   },
   "source": [
    "**Problem defintion**\n",
    "We are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills.\n",
    "\"Store in the next month\" is vage. I intepret it to mean that we should store a number in a column and a row, where row is the product id and column is the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "items_df = pd.read_csv('../input/items.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "sales_train_df = pd.read_csv('../input/sales_train.csv')\n",
    "item_categories_df = pd.read_csv('../input/item_categories.csv')\n",
    "shops_df = pd.read_csv('../input/shops.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "295ddfe6403d338f2f4ad265b41cdd657212c66a"
   },
   "source": [
    "## Describe the data ##\n",
    "sales_train:   \n",
    "    date:date  \n",
    "    date_block_num:[0-33 ]  \n",
    "    shop_id:integer describing the shop[0,59]   \n",
    "    item_id: has 21807 uniqe values  \n",
    "    ** item_cnt_day **: spans nont contonius from -22 to 2169  . ** What means negative numbers ? ** We can try to see how many uniqie items are returned.\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "aa4153726ba0697e6a51bd50f5fc98b691981ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date' 'date_block_num' 'shop_id' 'item_id' 'item_price' 'item_cnt_day']\n",
      "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
      "0  02.01.2013               0       59    22154      999.00           1.0\n",
      "1  03.01.2013               0       25     2552      899.00           1.0\n",
      "2  05.01.2013               0       25     2552      899.00          -1.0\n",
      "3  06.01.2013               0       25     2554     1709.05           1.0\n",
      "4  15.01.2013               0       25     2555     1099.00           1.0\n",
      "               date  date_block_num  shop_id  item_id  item_price  \\\n",
      "2935844  10.10.2015              33       25     7409       299.0   \n",
      "2935845  09.10.2015              33       25     7460       299.0   \n",
      "2935846  14.10.2015              33       25     7459       349.0   \n",
      "2935847  22.10.2015              33       25     7440       299.0   \n",
      "2935848  03.10.2015              33       25     7460       299.0   \n",
      "\n",
      "         item_cnt_day  \n",
      "2935844           1.0  \n",
      "2935845           1.0  \n",
      "2935846           1.0  \n",
      "2935847           1.0  \n",
      "2935848           1.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2935849 entries, 0 to 2935848\n",
      "Data columns (total 6 columns):\n",
      "date              object\n",
      "date_block_num    int64\n",
      "shop_id           int64\n",
      "item_id           int64\n",
      "item_price        float64\n",
      "item_cnt_day      float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 134.4+ MB\n",
      "None\n",
      "       date_block_num       shop_id       item_id    item_price  item_cnt_day\n",
      "count    2.935849e+06  2.935849e+06  2.935849e+06  2.935849e+06  2.935849e+06\n",
      "mean     1.456991e+01  3.300173e+01  1.019723e+04  8.908532e+02  1.242641e+00\n",
      "std      9.422988e+00  1.622697e+01  6.324297e+03  1.729800e+03  2.618834e+00\n",
      "min      0.000000e+00  0.000000e+00  0.000000e+00 -1.000000e+00 -2.200000e+01\n",
      "25%      7.000000e+00  2.200000e+01  4.476000e+03  2.490000e+02  1.000000e+00\n",
      "50%      1.400000e+01  3.100000e+01  9.343000e+03  3.990000e+02  1.000000e+00\n",
      "75%      2.300000e+01  4.700000e+01  1.568400e+04  9.990000e+02  1.000000e+00\n",
      "max      3.300000e+01  5.900000e+01  2.216900e+04  3.079800e+05  2.169000e+03\n",
      "21807\n",
      "60\n",
      "uniqe cnt_day[ -22.  -16.   -9.   -6.   -5.   -4.   -3.   -2.   -1.    1.    2.    3.\n",
      "    4.    5.    6.    7.    8.    9.   10.   11.   12.   13.   14.   15.\n",
      "   16.   17.   18.   19.   20.   21.   22.   23.   24.   25.   26.   27.\n",
      "   28.   29.   30.   31.   32.   33.   34.   35.   36.   37.   38.   39.\n",
      "   40.   41.   42.   43.   44.   45.   46.   47.   48.   49.   50.   51.\n",
      "   52.   53.   54.   55.   56.   57.   58.   59.   60.   61.   62.   63.\n",
      "   64.   65.   66.   67.   68.   69.   70.   71.   72.   73.   74.   75.\n",
      "   76.   77.   78.   79.   80.   81.   82.   83.   84.   85.   86.   87.\n",
      "   88.   89.   90.   91.   92.   93.   95.   96.   97.   98.   99.  100.\n",
      "  101.  102.  103.  104.  105.  106.  107.  108.  109.  110.  111.  112.\n",
      "  113.  114.  115.  116.  117.  118.  121.  124.  126.  127.  128.  129.\n",
      "  130.  131.  132.  133.  134.  135.  138.  139.  140.  142.  145.  146.\n",
      "  147.  148.  149.  150.  151.  153.  154.  156.  157.  161.  163.  164.\n",
      "  167.  168.  171.  179.  187.  194.  195.  200.  205.  207.  217.  222.\n",
      "  230.  231.  240.  242.  251.  255.  264.  288.  299.  300.  313.  325.\n",
      "  343.  401.  405.  412.  480.  500.  501.  502.  504.  508.  512.  533.\n",
      "  539.  624.  637.  669. 1000. 2169.]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[''] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-47840d398ed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'uniqe cnt_day'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msales_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_cnt_day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mreturned_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msales_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2721\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2723\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"[''] not in index\""
     ]
    }
   ],
   "source": [
    "print(sales_train_df.columns.values)\n",
    "print(sales_train_df.head())\n",
    "print(sales_train_df.tail())\n",
    "print(sales_train_df.info())\n",
    "print(sales_train_df.describe())\n",
    "print(len(np.unique(sales_train_df[['item_id']])))\n",
    "print(len(np.unique(sales_train_df[['shop_id']])))\n",
    "np.set_printoptions(precision=0, suppress=True)\n",
    "print( 'uniqe cnt_day' + str(np.unique(sales_train_df[['item_cnt_day']])))\n",
    "returned_items = sales_train_df.Where\n",
    "plt.plot(sales_train_df[[wh]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f199ba6e09f9f845dfd59a4d26e702ecaefb684"
   },
   "source": [
    "## Items data description ##  \n",
    "We have about 22170 different items in 84 different categories  \n",
    "** item_category_id **: [0-83]  \n",
    "** item_name **: each line unique => 22170 different values  \n",
    "** item_id **: each line unique   => [0 - 22169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "202418e3799beb85e9ff27617b79fe9f6c46c741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_name' 'item_id' 'item_category_id']\n",
      "                                           item_name  item_id  \\\n",
      "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
      "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
      "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
      "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
      "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
      "\n",
      "   item_category_id  \n",
      "0                40  \n",
      "1                76  \n",
      "2                40  \n",
      "3                40  \n",
      "4                40  \n",
      "                                               item_name  item_id  \\\n",
      "22165             Ядерный титбит 2 [PC, Цифровая версия]    22165   \n",
      "22166    Язык запросов 1С:Предприятия  [Цифровая версия]    22166   \n",
      "22167  Язык запросов 1С:Предприятия 8 (+CD). Хрустале...    22167   \n",
      "22168                                Яйцо для Little Inu    22168   \n",
      "22169                      Яйцо дракона (Игра престолов)    22169   \n",
      "\n",
      "       item_category_id  \n",
      "22165                31  \n",
      "22166                54  \n",
      "22167                49  \n",
      "22168                62  \n",
      "22169                69  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22170 entries, 0 to 22169\n",
      "Data columns (total 3 columns):\n",
      "item_name           22170 non-null object\n",
      "item_id             22170 non-null int64\n",
      "item_category_id    22170 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 519.7+ KB\n",
      "None\n",
      "           item_id  item_category_id\n",
      "count  22170.00000      22170.000000\n",
      "mean   11084.50000         46.290753\n",
      "std     6400.07207         15.941486\n",
      "min        0.00000          0.000000\n",
      "25%     5542.25000         37.000000\n",
      "50%    11084.50000         40.000000\n",
      "75%    16626.75000         58.000000\n",
      "max    22169.00000         83.000000\n",
      "                                                item_name\n",
      "count                                               22170\n",
      "unique                                              22170\n",
      "top     English today. Интерактивный словарь английско...\n",
      "freq                                                    1\n",
      "84\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "22170\n",
      "22170\n",
      "item_id    0\n",
      "dtype: int64\n",
      "item_id    22169\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(items_df.columns.values)\n",
    "print(items_df.head())\n",
    "print(items_df.tail())\n",
    "print(items_df.info())\n",
    "print(items_df.describe())\n",
    "print(items_df.describe(include=['O']))\n",
    "print( len(np.unique(items_df[['item_category_id']])))\n",
    "print( np.unique(items_df[['item_category_id']]))\n",
    "\n",
    "print( len(np.unique(items_df[['item_name']])))\n",
    "print( len(np.unique(items_df[['item_id']])))\n",
    "print( np.min(items_df[['item_id']]))\n",
    "print( np.max(items_df[['item_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bd5d9cc4eae154aa49394c12b70410ea2c7d2f6"
   },
   "source": [
    "## items_categories \n",
    "Names of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b4c92a6655843e88448a553355d5f8152b0b5595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_category_name' 'item_category_id']\n",
      "        item_category_name  item_category_id\n",
      "0  PC - Гарнитуры/Наушники                 0\n",
      "1         Аксессуары - PS2                 1\n",
      "2         Аксессуары - PS3                 2\n",
      "3         Аксессуары - PS4                 3\n",
      "4         Аксессуары - PSP                 4\n",
      "           item_category_name  item_category_id\n",
      "79                  Служебные                79\n",
      "80         Служебные - Билеты                80\n",
      "81    Чистые носители (шпиль)                81\n",
      "82  Чистые носители (штучные)                82\n",
      "83           Элементы питания                83\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 2 columns):\n",
      "item_category_name    84 non-null object\n",
      "item_category_id      84 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.4+ KB\n",
      "None\n",
      "       item_category_id\n",
      "count         84.000000\n",
      "mean          41.500000\n",
      "std           24.392622\n",
      "min            0.000000\n",
      "25%           20.750000\n",
      "50%           41.500000\n",
      "75%           62.250000\n",
      "max           83.000000\n"
     ]
    }
   ],
   "source": [
    "print(item_categories_df.columns.values)\n",
    "print(item_categories_df.head())\n",
    "print(item_categories_df.tail())\n",
    "print(item_categories_df.info())\n",
    "print(item_categories_df.describe())\n",
    "#print(len(np.unique(item_categories_df[['item_id']])))\n",
    "#print(len(np.unique(item_categories_df[['shop_id']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87e21e490233c01bbbfd1023717a3770e9b1e1a2"
   },
   "source": [
    "## shops ##  \n",
    "Contains names of the shops  \n",
    "Maybe there is something with the name of the shops, but hard to tell.  \n",
    "Maybe we can sort them by which is most similare  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "e7fc65dfd79a5b36722f01c79d5f0a2ccfba1752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shop_name' 'shop_id']\n",
      "                        shop_name  shop_id\n",
      "0   !Якутск Орджоникидзе, 56 фран        0\n",
      "1   !Якутск ТЦ \"Центральный\" фран        1\n",
      "2                Адыгея ТЦ \"Мега\"        2\n",
      "3  Балашиха ТРК \"Октябрь-Киномир\"        3\n",
      "4        Волжский ТЦ \"Волга Молл\"        4\n",
      "                   shop_name  shop_id\n",
      "55  Цифровой склад 1С-Онлайн       55\n",
      "56      Чехов ТРЦ \"Карнавал\"       56\n",
      "57   Якутск Орджоникидзе, 56       57\n",
      "58   Якутск ТЦ \"Центральный\"       58\n",
      "59    Ярославль ТЦ \"Альтаир\"       59\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 2 columns):\n",
      "shop_name    60 non-null object\n",
      "shop_id      60 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.0+ KB\n",
      "None\n",
      "         shop_id\n",
      "count  60.000000\n",
      "mean   29.500000\n",
      "std    17.464249\n",
      "min     0.000000\n",
      "25%    14.750000\n",
      "50%    29.500000\n",
      "75%    44.250000\n",
      "max    59.000000\n"
     ]
    }
   ],
   "source": [
    "print(shops_df.columns.values)\n",
    "print(shops_df.head())\n",
    "print(shops_df.tail())\n",
    "print(shops_df.info())\n",
    "print(shops_df.describe())\n",
    "#print(len(np.unique(shops_df[['item_id']])))\n",
    "#print(len(np.unique(shops_df[['shop_id']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c13d3e820da5da3bb3eabff0289377f09d6084ea"
   },
   "source": [
    "## test table ##  \n",
    "Is this a list of items sold ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "03ea17b8d296e6366a48eb7bb017de88cadc9d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID' 'shop_id' 'item_id']\n",
      "   ID  shop_id  item_id\n",
      "0   0        5     5037\n",
      "1   1        5     5320\n",
      "2   2        5     5233\n",
      "3   3        5     5232\n",
      "4   4        5     5268\n",
      "            ID  shop_id  item_id\n",
      "214195  214195       45    18454\n",
      "214196  214196       45    16188\n",
      "214197  214197       45    15757\n",
      "214198  214198       45    19648\n",
      "214199  214199       45      969\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214200 entries, 0 to 214199\n",
      "Data columns (total 3 columns):\n",
      "ID         214200 non-null int64\n",
      "shop_id    214200 non-null int64\n",
      "item_id    214200 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.9 MB\n",
      "None\n",
      "                  ID        shop_id        item_id\n",
      "count  214200.000000  214200.000000  214200.000000\n",
      "mean   107099.500000      31.642857   11019.398627\n",
      "std     61834.358168      17.561933    6252.644590\n",
      "min         0.000000       2.000000      30.000000\n",
      "25%     53549.750000      16.000000    5381.500000\n",
      "50%    107099.500000      34.500000   11203.000000\n",
      "75%    160649.250000      47.000000   16071.500000\n",
      "max    214199.000000      59.000000   22167.000000\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns.values)\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "print(test_df.info())\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b918625e3fe727ff62f96cf8d67cd941cfe0b28"
   },
   "source": [
    "## Summary of tables ##  \n",
    "Seems like sales_train is the only with valuable data.  \n",
    "Basically we have item, date and number of items sold and in which shops.\n",
    "### test table ###\n",
    "This table \n",
    "\n",
    "### Quality of data ###\n",
    "There are no missing data as in Titanic, except we might miss some dates.  \n",
    "#### Outliers ####  \n",
    "We can check for outliers by looking at histogram for each series, and removing those most away\n",
    "\n",
    "\n",
    "#### Few sales ###\n",
    "Seems like for some data there is few sales, \n",
    "we must be able to skip these or at least to \n",
    "\n",
    "### Restacking of data #### \n",
    "We need to pick out some time series for specific products.\n",
    "What we see is that some of the series are very short\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f11cf826051ce6b2a6569e1c3be44380cf3a90bc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0dc784e004e8a129e88dc88230903b7d9bfb6ebf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "0           1\n",
       "1           6\n",
       "2           2\n",
       "3           2\n",
       "4           1\n",
       "5           1\n",
       "6           1\n",
       "7           1\n",
       "8           2\n",
       "9           1\n",
       "10          1\n",
       "11          1\n",
       "12          1\n",
       "13          1\n",
       "14          1\n",
       "15          1\n",
       "16          1\n",
       "17          1\n",
       "18          1\n",
       "19          1\n",
       "20          1\n",
       "21          1\n",
       "22          1\n",
       "23          1\n",
       "24          1\n",
       "25          1\n",
       "26          1\n",
       "27         42\n",
       "28         86\n",
       "29         14\n",
       "         ... \n",
       "22140     290\n",
       "22141      48\n",
       "22142      10\n",
       "22143     647\n",
       "22144     112\n",
       "22145     286\n",
       "22146      29\n",
       "22147      63\n",
       "22148       2\n",
       "22149      35\n",
       "22150      58\n",
       "22151     283\n",
       "22152      84\n",
       "22153       9\n",
       "22154      59\n",
       "22155      75\n",
       "22156       4\n",
       "22157       4\n",
       "22158       1\n",
       "22159      14\n",
       "22160      49\n",
       "22161       1\n",
       "22162     560\n",
       "22163      71\n",
       "22164     408\n",
       "22165       2\n",
       "22166     270\n",
       "22167    1114\n",
       "22168       6\n",
       "22169       1\n",
       "Length: 21807, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_df.groupby(['item_id']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d905442de45bb6d7b03061e1667a1bef38e4501"
   },
   "source": [
    "## Scoring ##  \n",
    "How do we do the scoring ?   \n",
    "We modify the ** sample_submission ** table.\n",
    "\n",
    "## First attempt, take the latest sale and multiply with 30 !! ##  \n",
    "### test id ordering ###  \n",
    "The order of the rows in the submission is not logical. As a consequence we would have to pick the shop id and the item id from the test table in a for like loop.  \n",
    "This for loop should then look up in tables that we produce and put in the right numbers.  \n",
    " \n",
    " Back to our simplest strategy, which would be to take the latest sale for a product in a shop.  \n",
    " If the product has not been sold, well, then likely it will be sold the next month either !\n",
    " \n",
    "   ** as_index = False ** makes the grouped columns come out as ordinary colums\n",
    "  \n",
    "  ### Explanation of current query ###\n",
    "  -  Sort by date block (month nr) and group by shop-item-month, and sum nr sold items per day. \n",
    "  -  Group the results by shop-item, and pick the last, a small trick is used here as we use the combination of sort-grouby-last to find the grouped row with largest date-block-nr\n",
    "  - The results is a table with the latest data block when something was sold, and how much was sold then\t, it is store in **last**  \n",
    "    shop_id\titem_id\tdate_block_num\titem_cnt_day  \n",
    "    0\t0\t30\t1\t31.0  \n",
    "    1\t0\t31\t1\t11.0  \n",
    "- Now we want to remove all rows which do not have 33 , and assign in to **last2**\n",
    "- Then we should do an out join with thest test table, assign to **last3**  \n",
    "- Replace the Nan with 0  \n",
    "- Doing outer join, gave us too many actually, we are interested in only extra values from left, this is a **left join**\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bb6ba9569a599f151275a5f3ef0095587530cb6e"
   },
   "outputs": [],
   "source": [
    "last = sales_train_df.groupby(['shop_id','item_id','date_block_num'], as_index=False).agg({\"item_cnt_day\": \"sum\"}).sort_values('date_block_num').groupby(['shop_id','item_id'], as_index=False).last()\n",
    "last2=last[last['date_block_num'] == 33]\n",
    "answer = pd.merge(test_df,last2,on=['shop_id','item_id'],how='left').fillna(0)[['ID','item_cnt_day']]\n",
    "answer.columns =  ['ID','item_cnt_month']\n",
    "answer.to_csv('csv_to_submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
