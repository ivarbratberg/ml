{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Systemet finner ikke angitt bane: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-56c940884033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Systemet finner ikke angitt bane: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c1d6632e58738a9d1537c482b63059ef4111cdc"
   },
   "source": [
    "**Problem defintion**\n",
    "We are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills.\n",
    "\"Store in the next month\" is vage. I intepret it to mean that we should store a number in a column and a row, where row is the product id and column is the next month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "items_df = pd.read_csv('../input/items.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "sales_train_df = pd.read_csv('../input/sales_train.csv')\n",
    "item_categories_df = pd.read_csv('../input/item_categories.csv')\n",
    "shops_df = pd.read_csv('../input/shops.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "295ddfe6403d338f2f4ad265b41cdd657212c66a"
   },
   "source": [
    "## Describe the data ##\n",
    "sales_train:   \n",
    "    date:date  \n",
    "    date_block_num:[0-33 ]  \n",
    "    shop_id:integer describing the shop[0,59]   \n",
    "    item_id: has 21807 uniqe values  \n",
    "    ** item_cnt_day **: spans nont contonius from -22 to 2169  . ** What means negative numbers ? ** We can try to see how many uniqie items are returned.\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa4153726ba0697e6a51bd50f5fc98b691981ecf"
   },
   "outputs": [],
   "source": [
    "print(sales_train_df.columns.values)\n",
    "print(sales_train_df.head())\n",
    "print(sales_train_df.tail())\n",
    "print(sales_train_df.info())\n",
    "print(sales_train_df.describe())\n",
    "print(len(np.unique(sales_train_df[['item_id']])))\n",
    "print(len(np.unique(sales_train_df[['shop_id']])))\n",
    "np.set_printoptions(precision=0, suppress=True)\n",
    "print( 'uniqe cnt_day' + str(np.unique(sales_train_df[['item_cnt_day']])))\n",
    "returned_items = sales_train_df[['']]\n",
    "plt.plot(sales_train_df[[]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f199ba6e09f9f845dfd59a4d26e702ecaefb684"
   },
   "source": [
    "## Items data description ##  \n",
    "We have about 22170 different items in 84 different categories  \n",
    "** item_category_id **: [0-83]  \n",
    "** item_name **: each line unique => 22170 different values  \n",
    "** item_id **: each line unique   => [0 - 22169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "202418e3799beb85e9ff27617b79fe9f6c46c741"
   },
   "outputs": [],
   "source": [
    "print(items_df.columns.values)\n",
    "print(items_df.head())\n",
    "print(items_df.tail())\n",
    "print(items_df.info())\n",
    "print(items_df.describe())\n",
    "print(items_df.describe(include=['O']))\n",
    "print( len(np.unique(items_df[['item_category_id']])))\n",
    "print( np.unique(items_df[['item_category_id']]))\n",
    "\n",
    "print( len(np.unique(items_df[['item_name']])))\n",
    "print( len(np.unique(items_df[['item_id']])))\n",
    "print( np.min(items_df[['item_id']]))\n",
    "print( np.max(items_df[['item_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bd5d9cc4eae154aa49394c12b70410ea2c7d2f6"
   },
   "source": [
    "## items_categories \n",
    "Names of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4c92a6655843e88448a553355d5f8152b0b5595"
   },
   "outputs": [],
   "source": [
    "print(item_categories_df.columns.values)\n",
    "print(item_categories_df.head())\n",
    "print(item_categories_df.tail())\n",
    "print(item_categories_df.info())\n",
    "print(item_categories_df.describe())\n",
    "#print(len(np.unique(item_categories_df[['item_id']])))\n",
    "#print(len(np.unique(item_categories_df[['shop_id']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87e21e490233c01bbbfd1023717a3770e9b1e1a2"
   },
   "source": [
    "## shops ##  \n",
    "Contains names of the shops  \n",
    "Maybe there is something with the name of the shops, but hard to tell.  \n",
    "Maybe we can sort them by which is most similare  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7fc65dfd79a5b36722f01c79d5f0a2ccfba1752"
   },
   "outputs": [],
   "source": [
    "print(shops_df.columns.values)\n",
    "print(shops_df.head())\n",
    "print(shops_df.tail())\n",
    "print(shops_df.info())\n",
    "print(shops_df.describe())\n",
    "#print(len(np.unique(shops_df[['item_id']])))\n",
    "#print(len(np.unique(shops_df[['shop_id']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c13d3e820da5da3bb3eabff0289377f09d6084ea"
   },
   "source": [
    "## test table ##  \n",
    "Is this a list of items sold ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03ea17b8d296e6366a48eb7bb017de88cadc9d3b"
   },
   "outputs": [],
   "source": [
    "print(test_df.columns.values)\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "print(test_df.info())\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b918625e3fe727ff62f96cf8d67cd941cfe0b28"
   },
   "source": [
    "## Summary of tables ##  \n",
    "Seems like sales_train is the only with valuable data.  \n",
    "Basically we have item, date and number of items sold and in which shops.\n",
    "### test table ###\n",
    "This table \n",
    "\n",
    "### Quality of data ###\n",
    "There are no missing data as in Titanic, except we might miss some dates.  \n",
    "#### Outliers ####  \n",
    "We can check for outliers by looking at histogram for each series, and removing those most away\n",
    "\n",
    "\n",
    "#### Few sales ###\n",
    "Seems like for some data there is few sales, \n",
    "we must be able to skip these or at least to \n",
    "\n",
    "### Restacking of data #### \n",
    "We need to pick out some time series for specific products.\n",
    "What we see is that some of the series are very short\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f11cf826051ce6b2a6569e1c3be44380cf3a90bc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dc784e004e8a129e88dc88230903b7d9bfb6ebf"
   },
   "outputs": [],
   "source": [
    "sales_train_df.groupby(['item_id']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d905442de45bb6d7b03061e1667a1bef38e4501"
   },
   "source": [
    "## Scoring ##  \n",
    "How do we do the scoring ?   \n",
    "We modify the ** sample_submission ** table.\n",
    "\n",
    "## First attempt, take the latest sale and multiply with 30 !! ##  \n",
    "### test id ordering ###  \n",
    "The order of the rows in the submission is not logical. As a consequence we would have to pick the shop id and the item id from the test table in a for like loop.  \n",
    "This for loop should then look up in tables that we produce and put in the right numbers.  \n",
    " \n",
    " Back to our simplest strategy, which would be to take the latest sale for a product in a shop.  \n",
    " If the product has not been sold, well, then likely it will be sold the next month either !\n",
    " \n",
    "   ** as_index = False ** makes the grouped columns come out as ordinary colums\n",
    "  \n",
    "  ### Explanation of current query ###\n",
    "  -  Sort by date block (month nr) and group by shop-item-month, and sum nr sold items per day. \n",
    "  -  Group the results by shop-item, and pick the last, a small trick is used here as we use the combination of sort-grouby-last to find the grouped row with largest date-block-nr\n",
    "  - The results is a table with the latest data block when something was sold, and how much was sold then\t, it is store in **last**  \n",
    "    shop_id\titem_id\tdate_block_num\titem_cnt_day  \n",
    "    0\t0\t30\t1\t31.0  \n",
    "    1\t0\t31\t1\t11.0  \n",
    "- Now we want to remove all rows which do not have 33 , and assign in to **last2**\n",
    "- Then we should do an out join with thest test table, assign to **last3**  \n",
    "- Replace the Nan with 0  \n",
    "- Doing outer join, gave us too many actually, we are interested in only extra values from left, this is a **left join**\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb6ba9569a599f151275a5f3ef0095587530cb6e"
   },
   "outputs": [],
   "source": [
    "last = sales_train_df.groupby(['shop_id','item_id','date_block_num'], as_index=False).agg({\"item_cnt_day\": \"sum\"}).sort_values('date_block_num').groupby(['shop_id','item_id'], as_index=False).last()\n",
    "last2=last[last['date_block_num'] == 33]\n",
    "answer = pd.merge(test_df,last2,on=['shop_id','item_id'],how='left').fillna(0)[['ID','item_cnt_day']]\n",
    "answer.columns =  ['ID','item_cnt_month']\n",
    "answer.to_csv('csv_to_submit.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
